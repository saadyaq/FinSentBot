# ğŸ§  FinSentBot

**FinSentBot** est un systÃ¨me de trading automatique avancÃ© qui combine l'analyse de sentiment en temps rÃ©el des actualitÃ©s financiÃ¨res avec la collecte de donnÃ©es boursiÃ¨res historiques et en temps rÃ©el. Le projet utilise **Apache Kafka** pour la gestion des flux de donnÃ©es, **FinBERT** pour l'analyse de sentiment financier, et un modÃ¨le de gÃ©nÃ©ration de signaux de trading basÃ© sur l'apprentissage automatique.

---

## ğŸ“Š FonctionnalitÃ©s

### ğŸ”„ Collecte de donnÃ©es en temps rÃ©el
- **Prix d'actions** via Yahoo Finance API
- **Scraping d'articles** depuis CNBC, CoinDesk, Financial Times, et TechCrunch
- **DonnÃ©es historiques** extensives avec multiple pÃ©riodes et intervalles

### ğŸ§  Analyse intelligente
- **Analyse de sentiment** utilisant le modÃ¨le FinBERT (ProsusAI/finbert)
- **GÃ©nÃ©ration de signaux de trading** basÃ©e sur ML
- **Preprocessing avancÃ©** des donnÃ©es textuelles

### ğŸ“Š Visualisation et monitoring
- **Dashboard interactif** Streamlit
- **Interface Kafka UI** pour monitoring des topics
- **Logging complet** avec fichiers de logs rotatifs

---

## ğŸ—ï¸ Architecture du projet

```bash
FinSentBot/
â”œâ”€â”€ messaging/
â”‚   â”œâ”€â”€ producers/
â”‚   â”‚   â”œâ”€â”€ news_scraper_producer.py
â”‚   â”‚   â”œâ”€â”€ stock_price_producer.py
â”‚   â”‚   â””â”€â”€ scrapers/
â”‚   â”‚       â””â”€â”€ src/
â”‚   â”‚           â”œâ”€â”€ scraper_cnbc.py
â”‚   â”‚           â”œâ”€â”€ scraper_coindesk.py
â”‚   â”‚           â”œâ”€â”€ scraper_ft.py
â”‚   â”‚           â””â”€â”€ scraper_tc.py
â”‚   â””â”€â”€ consumers/
â”‚       â”œâ”€â”€ sentiment_analysis_consumer.py
â”‚       â””â”€â”€ trading_signal_consumer.py
â”‚
â”œâ”€â”€ TradingLogic/
â”‚   â”œâ”€â”€ SignalGenerator/
â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â”œâ”€â”€ prepare_dataset.py
â”‚   â””â”€â”€ trained_model.pth
â”‚
â”œâ”€â”€ nlp/
â”‚   â”œâ”€â”€ sentiment_model.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â””â”€â”€ test.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ news_sentiment.jsonl
â”‚   â”‚   â”œâ”€â”€ stock_prices.jsonl
â”‚   â”‚   â””â”€â”€ seen_symbols.json
â”‚   â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ historical_stock_price_collector.py
â”‚   â”‚   â”œâ”€â”€ integrate_historical_prices.py
â”‚   â”‚   â””â”€â”€ run_stock_expansion.py
â”‚   â””â”€â”€ training_datasets/
â”‚       â””â”€â”€ train.csv
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ kafka_config.py
â”‚   â””â”€â”€ settings.yaml
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ helpers.py
â”‚   â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ data_analytics.ipynb
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yaml
â””â”€â”€ README.md

---

## ğŸš€ DÃ©marrage rapide

### 1. Installation des dÃ©pendances

```bash
pip install -r requirements.txt
```

### 2. Lancement de l'infrastructure Kafka

```bash
docker-compose up -d
```

Cela dÃ©marre :
- **Kafka** sur le port 9092
- **Zookeeper** sur le port 2181  
- **Kafka UI** sur le port 8080 (interface web)

### 3. Test de la configuration

```bash
python test_send.py
```

Ce script envoie un message test sur le topic `raw_news` pour vÃ©rifier la connectivitÃ© Kafka.

### 4. Collecte de donnÃ©es historiques

Pour enrichir votre dataset avec des donnÃ©es historiques S&P 500 :

```bash
python data/scripts/historical_stock_price_collector.py
```

Ce script collecte automatiquement les prix historiques pour 100+ symboles avec diffÃ©rentes pÃ©riodes (1mo, 3mo, 6mo, 1y) et intervalles (1m, 5m, 30m, 1h).

### 5. GÃ©nÃ©ration du dataset d'entraÃ®nement

```bash
python TradingLogic/prepare_dataset.py
```

CrÃ©e le fichier `data/training_datasets/train.csv` avec les Ã©chantillons alignÃ©s par symbole et timestamps.

### 6. Lancement des producteurs et consommateurs

**Producteur de news :**
```bash
python messaging/producers/news_scraper_producer.py
```

**Producteur de prix :**
```bash
python messaging/producers/stock_price_producer.py
```

**Consommateur d'analyse de sentiment :**
```bash
python messaging/consumers/sentiment_analysis_consumer.py
```

**Consommateur de signaux de trading :**
```bash
python messaging/consumers/trading_signal_consumer.py
```

### 7. Dashboard de visualisation

```bash
streamlit run dashboard/app.py
```

---

## ğŸ”§ Technologies utilisÃ©es

- **Apache Kafka** - Streaming de donnÃ©es en temps rÃ©el
- **Python** - Langage principal  
- **FinBERT** (ProsusAI/finbert) - ModÃ¨le d'analyse de sentiment financier
- **PyTorch** - Framework de deep learning
- **Transformers** (HuggingFace) - ModÃ¨les NLP prÃ©-entraÃ®nÃ©s
- **yfinance** - API Yahoo Finance pour les donnÃ©es boursiÃ¨res
- **Streamlit** - Dashboard interactif
- **BeautifulSoup** - Web scraping
- **Pandas** - Manipulation de donnÃ©es
- **Docker** - Containerisation de Kafka

---

## ğŸ“ˆ Flux de donnÃ©es

1. **Collecte** : Les scrapers rÃ©cupÃ¨rent les articles depuis CNBC, CoinDesk, Financial Times, TechCrunch
2. **Streaming** : Les articles sont envoyÃ©s dans Kafka topic `raw_news`
3. **Analyse** : Le consommateur de sentiment analyse chaque article avec FinBERT
4. **Enrichissement** : Les prix d'actions correspondants sont collectÃ©s via Yahoo Finance
5. **Signaux** : Le gÃ©nÃ©rateur de signaux combine sentiment + prix pour produire Buy/Sell/Hold
6. **Visualisation** : Le dashboard affiche les rÃ©sultats en temps rÃ©el

---

## ğŸ—‚ï¸ Structure des donnÃ©es

### Articles de news (`news_sentiment.jsonl`)
```json
{
  "source": "CNBC",
  "title": "Market rallies on positive earnings",
  "content": "...",
  "url": "https://...",
  "timestamp": "2024-08-28T10:30:00",
  "sentiment_score": 0.7534
}
```

### Prix d'actions (`stock_prices.jsonl`)
```json
{
  "symbol": "AAPL",
  "timestamp": "2024-08-28T10:30:00",
  "price": 184.50,
  "open": 183.20,
  "high": 185.10,
  "low": 182.90,
  "volume": 1234567,
  "period": "1mo",
  "interval": "1h"
}
```

---

## ğŸ¯ Utilisation avancÃ©e

### Collecte de donnÃ©es historiques personnalisÃ©e

Le collecteur historique supporte plusieurs modes de fonctionnement :

```python
from data.scripts.historical_stock_price_collector import HistoricalStockCollector

collector = HistoricalStockCollector()
# Collecte massive S&P 500
df = collector.run_massive_collection(save_frequency=5)
```

### EntraÃ®nement du modÃ¨le de signaux

```bash
python TradingLogic/SignalGenerator/train.py
```

### Monitoring avec Kafka UI

AccÃ©dez Ã  http://localhost:8080 pour monitorer :
- Topics Kafka
- Messages en temps rÃ©el  
- Consommateurs actifs
- MÃ©triques de performance

---

## ğŸ“Š Logging et debugging

Les logs sont automatiquement gÃ©nÃ©rÃ©s dans `data/logs/` avec rotation quotidienne :
- `finsentbot_YYYYMMDD.log` - Logs applicatifs
- Niveaux : INFO, WARNING, ERROR
- Format : timestamp - niveau - message

---

## âš™ï¸ Configuration

### Kafka (`config/kafka_config.py`)
- Bootstrap servers
- Topics configuration
- Producer/Consumer settings

### Settings gÃ©nÃ©raux (`config/settings.yaml`)
- ParamÃ¨tres d'API
- Seuils de sentiment
- Intervalles de collecte
